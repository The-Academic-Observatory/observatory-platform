{# Copyright 2020 Curtin University
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Author: James Diprose -#}
version: '3.8'

{% if is_env_local -%}
{# Local settings -#}
x-environment: &environment
  # Airflow settings
  AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  AIRFLOW__CORE__SQL_ALCHEMY_CONN: "postgres://airflow:airflow@postgres:5432/airflow"
  AIRFLOW__CORE__FERNET_KEY: ${FERNET_KEY}
  AIRFLOW__CORE__AIRFLOW_HOME: ${AIRFLOW_HOME}
  AIRFLOW__CORE__LOAD_EXAMPLES: "False"
  AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS: "False"
  AIRFLOW__WEBSERVER__RBAC: "True"
  AIRFLOW__CELERY__BROKER_URL: "redis://:@redis:6379/0"
  AIRFLOW__CELERY__RESULT_BACKEND: "db+postgresql://airflow:airflow@postgres:5432/airflow"

  # Paths to google credentials and UI user settings
  GOOGLE_APPLICATION_CREDENTIALS: "/run/secrets/google_application_credentials.json"
  AIRFLOW_UI_USER_EMAIL: "airflow@airflow.com"
  AIRFLOW_UI_USER_PASSWORD: "airflow"

  # Connections
  {% for conn in config.airflow_connections -%}
  {{ conn.conn_name }}: {{ conn.value }}
  {% endfor -%}

  # Variables
  AIRFLOW_VAR_DATA_PATH: "/opt/observatory/data"
  {% for var in config.make_airflow_variables() -%}
  {{ var.env_var_name }}: '{{ var.value }}'
  {% endfor %}

x-network-mode: &networks
  networks:
    - {{ docker_network_name }}

{% if not docker_network_is_external -%}
networks:
  {{ docker_network_name }}:
    name: {{ docker_network_name }}
    driver: bridge
{% else -%}
networks:
  {{ docker_network_name }}:
    external: true
{% endif -%}

{% else -%}
{# Cloud settings #}
x-environment: &environment
  # Airflow settings
  AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  AIRFLOW__CORE__SQL_ALCHEMY_CONN: "postgres://airflow:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}:5432/airflow"
  AIRFLOW__CORE__FERNET_KEY: "${FERNET_KEY}"
  AIRFLOW__CORE__AIRFLOW_HOME: ${AIRFLOW_HOME}
  AIRFLOW__CORE__LOAD_EXAMPLES: "False"
  AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS: "False"
  AIRFLOW__WEBSERVER__RBAC: "True"
  AIRFLOW__CELERY__BROKER_URL: "redis://:@${REDIS_HOSTNAME}:6379/0"
  AIRFLOW__CELERY__RESULT_BACKEND: "db+postgresql://airflow:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}:5432/airflow"
  AIRFLOW__SECRETS__BACKEND: "airflow.contrib.secrets.gcp_secrets_manager.CloudSecretsManagerBackend"
  AIRFLOW__SECRETS__BACKEND_KWARGS: "{'connections_prefix': 'airflow-connections', 'variables_prefix': 'airflow-variables', 'sep': '-'}"

  # Paths to google credentials and UI user settings
  GOOGLE_APPLICATION_CREDENTIALS: "/run/secrets/google_application_credentials.json"
  AIRFLOW_UI_USER_EMAIL: ${AIRFLOW_UI_USER_EMAIL}
  AIRFLOW_UI_USER_PASSWORD: ${AIRFLOW_UI_USER_PASSWORD}

  # Variables
  AIRFLOW_VAR_DATA_PATH: "/opt/observatory/data"
  AIRFLOW_VAR_DAGS_MODULE_NAMES: ${AIRFLOW_VAR_DAGS_MODULE_NAMES}
  {% for var in config.make_airflow_variables() -%}
  {{ var.env_var_name }}: {{ var.value }}
  {% endfor %}

x-network-mode: &networks
  network_mode: "host"

networks:
  {{ docker_network_name }}:
    name: {{ docker_network_name }}
    driver: bridge
{% endif -%}

x-volumes: &volumes
  - "${HOST_LOGS_PATH}:/opt/airflow/logs"
  - "${HOST_DAGS_PATH}:/opt/airflow/dags"
  - "${HOST_DATA_PATH}:/opt/observatory/data"
  - "${HOST_PACKAGE_PATH}:/opt/observatory/observatory-platform"
  {# Creates the volumes for local projects -#}
  {% for project in config.dags_projects -%}
  {% if project.type == 'local' -%}
  - "{{ project.path }}:/opt/observatory/{{ project.package_name }}"
  {% endif -%}
  {% endfor %}

x-build: &build
  context: .
  dockerfile: Dockerfile.observatory
  args:
    - HOST_USER_ID=${HOST_USER_ID}
    - HOST_GROUP_ID=${HOST_GROUP_ID}

services:
  redis:
    image: "redis:6.0.5"
    restart: always
    ports:
      - ${HOST_REDIS_PORT}:6379
    networks:
      - {{ docker_network_name }}

  flower:
    image: apache/airflow:1.10.12-python3.7
    environment: *environment
    restart: always
    networks:
      - {{ docker_network_name }}
    depends_on:
      - redis
    ports:
      - ${HOST_FLOWER_UI_PORT}:5555
    command: flower

  webserver:
    build: *build
    environment: *environment
    volumes: *volumes
    restart: always
    networks:
      - {{ docker_network_name }}
    depends_on:
      - redis
    {% if config.google_cloud.credentials is not none -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    ports:
      - ${HOST_AIRFLOW_UI_PORT}:8080
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /opt/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3

  scheduler:
    build: *build
    environment: *environment
    volumes: *volumes
    restart: always
    networks:
      - {{ docker_network_name }}
    depends_on:
      - webserver
    {% if config.google_cloud.credentials is not none -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    command: scheduler

  worker_local:
    build: *build
    environment: *environment
    volumes: *volumes
    restart: always
    <<: *networks
    depends_on:
      - scheduler
    {% if config.google_cloud.credentials is not none -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    command: worker -q default

  worker_remote:
    build: *build
    environment: *environment
    volumes: *volumes
    restart: always
    <<: *networks
    {% if config.google_cloud.credentials is not none -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    command: worker -q remote_queue

  elasticsearch:
    image: "docker.elastic.co/elasticsearch/elasticsearch:7.9.0"
    restart: always
    volumes:
      - "${HOST_DATA_PATH}/elastic:/usr/share/elasticsearch/data"
      - "./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml"
    ports:
      - ${HOST_ELASTIC_PORT}:9200
    networks:
      - {{ docker_network_name }}
    environment:
      - discovery.type=single-node

  kibana:
    image: "docker.elastic.co/kibana/kibana:7.9.0"
    restart: always
    ports:
      - ${HOST_KIBANA_PORT}:5601
    networks:
      - {{ docker_network_name }}

  postgres:
    image: postgres:12.2
    environment:
      - POSTGRES_DB=airflow
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
    volumes:
      - ${HOST_POSTGRES_PATH}:/var/lib/postgresql/data
    restart: always
    networks:
      - {{ docker_network_name }}

{% if config.google_cloud.credentials is not none -%}
secrets:
  google_application_credentials.json:
    file: ${HOST_GOOGLE_APPLICATION_CREDENTIALS}
{% endif -%}