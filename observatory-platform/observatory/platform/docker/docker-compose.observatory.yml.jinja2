{# Copyright 2020 Curtin University
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Author: James Diprose -#}
version: '3.8'

{# Values same for different environments #}
{%- set postgres_user="observatory" -%}
{%- set airflow_db_name="airflow" -%}
{%- set postgres_password="${POSTGRES_PASSWORD}" -%}
{%- set airflow_ui_user_email="${AIRFLOW_UI_USER_EMAIL}" -%}
{%- set airflow_ui_user_password="${AIRFLOW_UI_USER_PASSWORD}" -%}

{# Values different in different environments #}
{%- if config.backend.type.value == 'local' -%}

{%- set host_data_path="${HOST_OBSERVATORY_HOME}/data" -%}
{%- set host_logs_path="${HOST_OBSERVATORY_HOME}/logs" -%}
{%- set host_postgres_path="${HOST_OBSERVATORY_HOME}/postgres" -%}
{%- set host_dags_path="${HOST_DAGS_PATH}" -%}
{%- set host_platform_package_path="${HOST_PLATFORM_PACKAGE_PATH}" -%}
{%- set host_api_package_path="${HOST_API_PACKAGE_PATH}" -%}
{%- set google_application_credentials="${HOST_GOOGLE_APPLICATION_CREDENTIALS}" -%}
{%- set postgres_hostname="postgres" -%}
{%- set redis_hostname="redis" -%}

{%- else -%}

{%- set host_data_path="/opt/observatory/data" -%}
{%- set host_logs_path="/opt/airflow/logs" -%}
{%- set host_dags_path="/opt/observatory-platform/observatory/platform/dags" -%}
{%- set host_platform_package_path="/opt/observatory-platform" -%}
{%- set host_api_package_path="/opt/observatory-api" -%}
{%- set google_application_credentials="/opt/observatory/google_application_credentials.json" -%}
{%- set postgres_hostname="${POSTGRES_HOSTNAME}" -%}
{%- set redis_hostname="${REDIS_HOSTNAME}" -%}

{%- endif -%}

{# Local settings -#}
x-environment: &environment
  # Airflow settings
  AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  AIRFLOW__CORE__SQL_ALCHEMY_CONN: "postgres+psycopg2://{{ postgres_user }}:{{ postgres_password }}@{{ postgres_hostname }}:5432/{{ airflow_db_name }}"
  AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
  AIRFLOW__CORE__AIRFLOW_HOME: /opt/airflow
  AIRFLOW__CORE__LOAD_EXAMPLES: "False"
  AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS: "False"
  AIRFLOW__WEBSERVER__RBAC: "True"
  AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
  AIRFLOW__CELERY__BROKER_URL: "redis://:@{{ redis_hostname }}:6379/0"
  AIRFLOW__CELERY__RESULT_BACKEND: "db+postgresql://{{ postgres_user }}:{{ postgres_password }}@{{ postgres_hostname }}:5432/{{ airflow_db_name }}"
  {%- if config.backend.type.value == 'terraform' %}
  AIRFLOW__CORE__REMOTE_LOGGING: "True"
  AIRFLOW__CORE__REMOTE_BASE_LOG_FOLDER: "gs://${AIRFLOW_VAR_AIRFLOW_BUCKET}/logs"
  AIRFLOW__CORE__REMOTE_LOG_CONN_ID: "google_cloud_observatory"
  AIRFLOW__SECRETS__BACKEND: "observatory.platform.airflow.secret_manager.CloudSecretManagerBackend"
  AIRFLOW__SECRETS__BACKEND_KWARGS: "{'connections_prefix': 'airflow-connections', 'variables_prefix': 'airflow-variables', 'sep': '-'}"
  {%- endif %}

  # Paths to google credentials and UI user settings
  GOOGLE_APPLICATION_CREDENTIALS: "/run/secrets/google_application_credentials.json"
  AIRFLOW_UI_USER_EMAIL: "{{ airflow_ui_user_email }}"
  AIRFLOW_UI_USER_PASSWORD: "{{ airflow_ui_user_password }}"

  {%- if config.backend.type.value == 'local' %}
  # Connections
  {%- for conn in config.airflow_connections %}
  {{ conn.conn_name }}: {{ '${' + conn.conn_name + '}' }}
  {%- endfor %}
  {%- endif %}

  # Variables
  AIRFLOW_VAR_DATA_PATH: "/opt/observatory/data"
  AIRFLOW_VAR_DAGS_MODULE_NAMES: {{ dags_projects_to_str(config.dags_projects)  }}
  {%- if config.backend.type.value == 'terraform' %}
  AIRFLOW_VAR_DOWNLOAD_BUCKET: ${AIRFLOW_VAR_DOWNLOAD_BUCKET}
  AIRFLOW_VAR_TRANSFORM_BUCKET: ${AIRFLOW_VAR_TRANSFORM_BUCKET}
  {%- endif %}
  {%- for var in config.make_airflow_variables() %}
  {%- if config.backend.type.value == 'local' %}
  {{ var.env_var_name }}: '{{ var.value }}'
  {%- else %}
  {{ var.env_var_name }}: {{ '${' + var.env_var_name + '}' }}
  {%- endif %}
  {%- endfor %}

x-volumes: &volumes
  - "{{ host_logs_path }}:/opt/airflow/logs"
  - "{{ host_dags_path }}:/opt/airflow/dags"
  - "{{ host_data_path }}:/opt/observatory/data"
  - "{{ host_platform_package_path }}:/opt/observatory-platform"
  - "{{ host_api_package_path }}:/opt/observatory-api"
  # Volume mappings for DAGs projects:
  {%- for project in config.dags_projects %}
  {%- if project.type == 'local' %}
  {%- if config.backend.type.value == 'local' %}
  - "{{ project.path }}:/opt/{{ project.package_name }}"
  {%- else %}
  - "/opt/{{ project.package_name }}:/opt/{{ project.package_name }}"
  {%- endif %}
  {%- endif %}
  {%- endfor %}

{% if config.backend.type.value == 'local' %}
{# Local network #}
x-network-mode: &networks
  networks:
    - {{ docker_network_name }}

{%- else %}

{#- Cloud network -#}
x-network-mode: &networks
  network_mode: "host"

{%- endif -%}

{%- if config.backend.type.value == 'terraform' or not docker_network_is_external %}
{# Cloud network or not external network #}
networks:
  {{ docker_network_name }}:
    name: {{ docker_network_name }}
    driver: bridge
{%- else %}
networks:
  {{ docker_network_name }}:
    external: true
{%- endif %}

x-build: &build
  context: .
  dockerfile: Dockerfile.observatory
  args:
    - HOST_USER_ID=${HOST_USER_ID}
    - HOST_GROUP_ID=${HOST_GROUP_ID}

services:
  redis:
    image: redis:latest
    restart: always
    ports:
      - ${HOST_REDIS_PORT}:6379
    networks:
      - {{ docker_network_name }}
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50

  flower:
    image: apache/airflow:2.1.3-python3.8
    environment: *environment
    restart: always
    networks:
      - {{ docker_network_name }}
    depends_on:
      redis:
        condition: service_healthy
      {% if config.backend.type.value == 'local' -%}
      postgres:
        condition: service_healthy
      {%- endif %}
    ports:
      - ${HOST_FLOWER_UI_PORT}:5555
    command: celery flower
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: 10s
      timeout: 10s
      retries: 5

  webserver:
    build: *build
    environment: *environment
    volumes: *volumes
    restart: always
    networks:
      - {{ docker_network_name }}
    depends_on:
      redis:
        condition: service_healthy
      {% if config.backend.type.value == 'local' -%}
      postgres:
        condition: service_healthy
      {%- endif %}
    {% if config.google_cloud.credentials is not none -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    ports:
      - ${HOST_AIRFLOW_UI_PORT}:8080
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /opt/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3

  scheduler:
    build: *build
    environment: *environment
    volumes: *volumes
    restart: always
    networks:
      - {{ docker_network_name }}
    depends_on:
      webserver:
        condition: service_healthy
    {% if config.google_cloud.credentials is not none -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    command: scheduler

  worker_local:
    build: *build
    environment: *environment
    volumes: *volumes
    restart: always
    <<: *networks
    depends_on:
      - scheduler
    {% if config.google_cloud.credentials is not none -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    command: celery worker -q default

  worker_remote:
    build: *build
    environment: *environment
    volumes: *volumes
    restart: always
    <<: *networks
    {% if config.google_cloud.credentials is not none -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    command: celery worker -q remote_queue

  {% if config.backend.type.value == 'local' -%}
  elasticsearch:
    image: "docker.elastic.co/elasticsearch/elasticsearch:7.13.3"
    restart: always
    volumes:
      - "{{ host_data_path }}/elastic:/usr/share/elasticsearch/data"
      - "./elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml"
    ports:
      - ${HOST_ELASTIC_PORT}:9200
    networks:
      - {{ docker_network_name }}
    environment:
      - discovery.type=single-node

  kibana:
    image: "docker.elastic.co/kibana/kibana:7.13.3"
    restart: always
    ports:
      - ${HOST_KIBANA_PORT}:5601
    networks:
      - {{ docker_network_name }}

  postgres:
    image: postgres:12.2
    environment:
      - POSTGRES_DB={{ airflow_db_name }}
      - POSTGRES_USER={{ postgres_user }}
      - POSTGRES_PASSWORD={{ postgres_password }}
    volumes:
      - {{ host_postgres_path }}:/var/lib/postgresql/data
    restart: always
    networks:
      - {{ docker_network_name }}
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
  {%- endif %}

{% if config.google_cloud.credentials is not none -%}
secrets:
  google_application_credentials.json:
    file: {{ google_application_credentials }}
{%- endif %}
