{# Copyright 2020 Curtin University
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Author: James Diprose -#}
version: '3.8'

x-environment: &environment
  # Airflow settings
  AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  AIRFLOW__CORE__SQL_ALCHEMY_CONN: "postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}:5432/airflow"
  AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
  AIRFLOW__CORE__LOAD_EXAMPLES: "False"
  AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS: "False"
  AIRFLOW__CORE__EXECUTE_TASKS_NEW_PYTHON_INTERPRETER: "True"
  AIRFLOW__WEBSERVER__RBAC: "True"
  AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
  AIRFLOW__CELERY__BROKER_URL: "redis://:@${REDIS_HOSTNAME}:6379/0"
  AIRFLOW__CELERY__RESULT_BACKEND: "db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}:5432/airflow"
  AIRFLOW__CELERY_BROKER_TRANSPORT_OPTIONS__VISIBILITY_TIMEOUT: 259200
  AIRFLOW__API__AUTH_BACKEND: airflow.api.auth.backend.basic_auth
  {%- if config.backend.type.value == 'terraform' %}
  AIRFLOW__LOGGING__REMOTE_LOGGING: "True"
  AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER: "gs://${AIRFLOW_VAR_AIRFLOW_BUCKET}/logs"
  AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID: "google_cloud_observatory"
  AIRFLOW__SECRETS__BACKEND: "airflow.providers.google.cloud.secrets.secret_manager.CloudSecretManagerBackend"
  AIRFLOW__SECRETS__BACKEND_KWARGS: "{'connections_prefix': 'airflow-connections', 'variables_prefix': 'airflow-variables', 'sep': '-'}"
  {%- endif %}
  # Set Airflow DAGs folder to installed observatory platform dags
  {%- if config.observatory.package_type != 'editable' %}
  AIRFLOW__CORE__DAGS_FOLDER: "/home/airflow/.local/lib/python3.8/site-packages/observatory/platform/dags"
  {%- endif %}

  # Paths to google credentials and UI user settings
  GOOGLE_APPLICATION_CREDENTIALS: "/run/secrets/google_application_credentials.json"

  {%- if config.backend.type.value == 'local' %}
  # Connections
  {%- for conn in config.airflow_connections %}
  {{ conn.conn_name }}: {{ '${' + conn.conn_name + '}' }}
  {%- endfor %}

  {%- endif %}

  # Variables
  AIRFLOW_VAR_DATA_PATH: "/opt/observatory/data"
  {%- for var in config.make_airflow_variables() %}
  {%- if config.backend.type.value == 'local' %}
  {{ var.env_var_name }}: '{{ var.value }}'
  {%- else %}
  {{ var.env_var_name }}: {{ '${' + var.env_var_name + '}' }}
  {%- endif %}
  {%- endfor %}

x-volumes: &volumes
  - "${HOST_LOGS_PATH}:/opt/airflow/logs"
  - "${HOST_DATA_PATH}:/opt/observatory/data"

  # Volume mapping when observatory installed in editable mode
  {%- if config.backend.type.value == 'local' and config.observatory.package_type == 'editable' %}
  - "{{ config.observatory.host_package }}/observatory/platform/dags:/opt/airflow/dags"
  {%- elif config.backend.type.value == 'terraform' and config.observatory.package_type == 'editable'  %}
  - "/opt/observatory-platform/observatory/platform/dags:/opt/airflow/dags"
  {%- endif -%}

  # Volume mappings for Python packages, incl observatory-platform and dags projects:
  {%- for package in config.python_packages %}
  {%- if config.backend.type.value == 'local' and package.type == 'editable' %}
  - "{{ package.host_package }}:/opt/{{ package.name }}"
  {%- elif config.backend.type.value == 'terraform' and package.type == 'editable'  %}
  - "/opt/{{ package.name }}:/opt/{{ package.name }}"
  {%- endif -%}
  {%- endfor %}

x-depends-on: &depends-on
  redis:
    condition: service_healthy
  {% if config.backend.type.value == 'local' -%}
  postgres:
    condition: service_healthy
  {%- endif %}

{% if config.backend.type.value == 'local' %}
{# Local network #}
x-network-mode: &networks
  networks:
    - {{ config.observatory.docker_network_name }}

{%- else %}

{#- Cloud network -#}
x-network-mode: &networks
  network_mode: "host"

{%- endif -%}

{%- if config.backend.type.value == 'terraform' or not config.observatory.docker_network_is_external %}
{# Cloud network or not external network #}
networks:
  {{ config.observatory.docker_network_name }}:
    name: {{ config.observatory.docker_network_name }}
    driver: bridge
{%- else %}
networks:
  {{ config.observatory.docker_network_name }}:
    external: true
{%- endif %}

x-build: &build
  context: .
  dockerfile: Dockerfile.observatory
  args:
    - HOST_USER_ID=${HOST_USER_ID}

services:
  redis:
    image: redis:latest
    restart: always
    ports:
      - ${HOST_REDIS_PORT}:6379
    networks:
      - {{ config.observatory.docker_network_name }}
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50

  flower:
    image: apache/airflow:2.2.1-python3.8
    environment: *environment
    restart: always
    networks:
      - {{ config.observatory.docker_network_name }}
    depends_on: *depends-on
    ports:
      - ${HOST_FLOWER_UI_PORT}:5555
    command: celery flower
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: 30s
      timeout: 10s
      retries: 5
    {% if (config.google_cloud is not none) and (config.google_cloud.credentials is not none) -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}

  webserver:
    image: apache/airflow:2.2.1-python3.8
    environment: *environment
    restart: always
    networks:
      - {{ config.observatory.docker_network_name }}
    depends_on: *depends-on
    {% if (config.google_cloud is not none) and (config.google_cloud.credentials is not none) -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    ports:
      - ${HOST_AIRFLOW_UI_PORT}:8080
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /opt/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 30

  airflow_init:
    image: apache/airflow:2.2.1-python3.8
    environment:
      <<: *environment
      _AIRFLOW_DB_UPGRADE: "true"
      _AIRFLOW_WWW_USER_CREATE: "true"
      _AIRFLOW_WWW_USER_USERNAME: ${AIRFLOW_UI_USER_EMAIL}
      _AIRFLOW_WWW_USER_PASSWORD: ${AIRFLOW_UI_USER_PASSWORD}
    networks:
      - {{ config.observatory.docker_network_name }}
    depends_on: *depends-on
    command: version

  scheduler:
    build: *build
    environment: *environment
    volumes: *volumes
    restart: always
    networks:
      - {{ config.observatory.docker_network_name }}
    depends_on:
      webserver:
        condition: service_healthy
    {% if (config.google_cloud is not none) and (config.google_cloud.credentials is not none) -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    command: scheduler

  worker_local:
    build: *build
    environment: *environment
    volumes: *volumes
    restart: always
    <<: *networks
    depends_on:
      - scheduler
    {% if (config.google_cloud is not none) and (config.google_cloud.credentials is not none) -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    command: celery worker -q default

  worker_remote:
    build: *build
    environment: *environment
    volumes: *volumes
    restart: always
    <<: *networks
    {% if (config.google_cloud is not none) and (config.google_cloud.credentials is not none) -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    command: celery worker -q remote_queue

  apiserver:
    build:
      context: .
      dockerfile: Dockerfile.apiserver
      args:
        - HOST_USER_ID=${HOST_USER_ID}
    environment:
      - API_SERVER_DB=observatory
      - BASE_DB_URI=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}/postgres
      - OBSERVATORY_DB_URI=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}/observatory
      - OBSERVATORY_API_PORT=5002
    volumes: *volumes
    restart: always
    ports:
      - ${HOST_API_SERVER_PORT}:5002
    networks:
      - {{ config.observatory.docker_network_name }}
    {% if config.backend.type.value == 'local' %} 
    depends_on:
      postgres:
        condition: service_healthy
    {% endif %}
    healthcheck:
      test: ["CMD", "nc", "-z", "-v", "apiserver", "5002"]
      interval: 30s
      retries: 20
    command: apiserver
    entrypoint: /entrypoint-api.sh

{% if config.backend.type.value == 'local' %} 

  postgres:
    image: postgres:12.2
    environment:
      - POSTGRES_DB=airflow
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - ${HOST_POSTGRES_PATH}:/var/lib/postgresql/data
    restart: always
    networks:
      - {{ config.observatory.docker_network_name }}
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}", "-d", "airflow"]
      interval: 5s
      retries: 5

  seed_db:
    build:
      context: .
      dockerfile: Dockerfile.seed_db
      args:
        - HOST_USER_ID=${HOST_USER_ID}
    environment:
      - API_URI="http://apiserver:5002"
    volumes: *volumes
    <<: *networks
    depends_on:
      apiserver:
        condition: service_healthy
{%- endif %}


{% if (config.google_cloud is not none) and (config.google_cloud.credentials is not none) -%}
secrets:
  google_application_credentials.json:
    file: ${HOST_GOOGLE_APPLICATION_CREDENTIALS}
{%- endif %}
