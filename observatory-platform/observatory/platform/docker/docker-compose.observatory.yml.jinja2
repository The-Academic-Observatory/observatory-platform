{# Copyright 2020-2023 Curtin University
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Author: James Diprose -#}
version: '3.8'

x-environment: &environment
  # Airflow settings
  AIRFLOW__CORE__EXECUTOR: CeleryExecutor
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: "postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}:5432/airflow"
  AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW_FERNET_KEY}
  AIRFLOW__CORE__LOAD_EXAMPLES: "False"
  AIRFLOW__CORE__LOAD_DEFAULT_CONNECTIONS: "False"
  AIRFLOW__CORE__EXECUTE_TASKS_NEW_PYTHON_INTERPRETER: "True"
  AIRFLOW__WEBSERVER__RBAC: "True"
  AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW_SECRET_KEY}
  AIRFLOW__CELERY__BROKER_URL: "redis://:@${REDIS_HOSTNAME}:6379/0"
  AIRFLOW__CELERY__RESULT_BACKEND: "db+postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}:5432/airflow"
  AIRFLOW__CELERY_BROKER_TRANSPORT_OPTIONS__VISIBILITY_TIMEOUT: 259200
  AIRFLOW__API__AUTH_BACKENDS: airflow.api.auth.backend.basic_auth
  {%- if config.backend.type.value == 'terraform' %}
  AIRFLOW__LOGGING__REMOTE_LOGGING: "True"
  AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER: "gs://${AIRFLOW_LOGGING_BUCKET}/logs"
  AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID: "google_cloud_observatory"
  {%- endif %}
  # Set Airflow DAGs folder to installed observatory platform dags
  {%- if config.observatory.package_type != 'editable' %}
  AIRFLOW__CORE__DAGS_FOLDER: "/home/airflow/.local/lib/python3.10/site-packages/observatory/platform/dags"
  {%- endif %}

  # Paths to google credentials and UI user settings
  GOOGLE_APPLICATION_CREDENTIALS: "/run/secrets/google_application_credentials.json"

  # Variables
  AIRFLOW_VAR_DATA_PATH: "/opt/observatory/data"
  AIRFLOW_VAR_WORKFLOWS: ${AIRFLOW_VAR_WORKFLOWS}
  AIRFLOW_VAR_DAGS_MODULE_NAMES: ${AIRFLOW_VAR_DAGS_MODULE_NAMES}

x-volumes: &volumes
  - "${HOST_LOGS_PATH}:/opt/airflow/logs"
  - "${HOST_DATA_PATH}:/opt/observatory/data"

  # Volume mapping when observatory installed in editable mode
  {%- if config.backend.type.value == 'local' and config.observatory.package_type == 'editable' %}
  - "{{ config.observatory.host_package }}/observatory/platform/dags:/opt/airflow/dags"
  {%- elif config.backend.type.value == 'terraform' and config.observatory.package_type == 'editable'  %}
  - "/opt/observatory-platform/observatory/platform/dags:/opt/airflow/dags"
  {%- endif -%}

  # Volume mappings for Python packages, incl observatory-platform and dags projects:
  {%- for package in config.python_packages %}
  {%- if config.backend.type.value == 'local' and package.type == 'editable' %}
  - "{{ package.host_package }}:/opt/{{ package.name }}"
  {%- elif config.backend.type.value == 'terraform' and package.type == 'editable'  %}
  - "/opt/{{ package.name }}:/opt/{{ package.name }}"
  {%- endif -%}
  {%- endfor %}

x-depends-on: &depends-on
  redis:
    condition: service_healthy
  {% if config.backend.type.value == 'local' -%}
  postgres:
    condition: service_healthy
  {%- endif %}

{% if config.backend.type.value == 'local' %}
{# Local network #}
x-network-mode: &networks
  networks:
    - {{ config.observatory.docker_network_name }}

{%- else %}

{#- Cloud network -#}
x-network-mode: &networks
  network_mode: "host"

{%- endif -%}

{%- if config.backend.type.value == 'terraform' or not config.observatory.docker_network_is_external %}
{# Cloud network or not external network #}
networks:
  {{ config.observatory.docker_network_name }}:
    name: {{ config.observatory.docker_network_name }}
    driver: bridge
{%- else %}
networks:
  {{ config.observatory.docker_network_name }}:
    external: true
{%- endif %}

x-build: &build
  context: .
  dockerfile: Dockerfile.observatory
  args:
    - HOST_USER_ID=${HOST_USER_ID}

services:
  redis:
    container_name: redis
    hostname: redis
    image: redis:latest
    restart: always
    ports:
      - ${HOST_REDIS_PORT}:6379
    networks:
      - {{ config.observatory.docker_network_name }}
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 30s
      retries: 50

  flower:
    container_name: flower
    hostname: flower
    image: apache/airflow:{{ airflow_version }}-python{{ python_version }}
    environment: *environment
    restart: always
    networks:
      - {{ config.observatory.docker_network_name }}
    ports:
      - ${HOST_FLOWER_UI_PORT}:5555
    command: celery flower
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:5555/"]
      interval: 30s
      timeout: 10s
      retries: 5
    {% if (config.google_cloud is not none) and (config.google_cloud.credentials is not none) -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    depends_on:
      <<: *depends-on
      airflow_init:
        condition: service_completed_successfully

  webserver:
    container_name: webserver
    hostname: webserver 
    image: apache/airflow:{{ airflow_version }}-python{{ python_version }}
    volumes: *volumes
    environment: *environment
    restart: always
    networks:
      - {{ config.observatory.docker_network_name }}
    {% if (config.google_cloud is not none) and (config.google_cloud.credentials is not none) -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    ports:
      - ${HOST_AIRFLOW_UI_PORT}:8080
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /opt/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 30
    depends_on:
      <<: *depends-on
      airflow_init:
        condition: service_completed_successfully

  airflow_init:
    container_name: airflow_init
    hostname: airflow_init
    image: apache/airflow:{{ airflow_version }}-python{{ python_version }}
    environment:
      <<: *environment
      _AIRFLOW_DB_UPGRADE: "true"
      _AIRFLOW_WWW_USER_CREATE: "true"
      _AIRFLOW_WWW_USER_USERNAME: ${AIRFLOW_UI_USER_EMAIL}
      _AIRFLOW_WWW_USER_PASSWORD: ${AIRFLOW_UI_USER_PASSWORD}
    networks:
      - {{ config.observatory.docker_network_name }}
    command: version
    depends_on: *depends-on

  scheduler:  
    container_name: scheduler
    hostname: scheduler
    build: *build
    environment: *environment
    volumes: *volumes
    restart: always
    networks:
      - {{ config.observatory.docker_network_name }}
    {% if (config.google_cloud is not none) and (config.google_cloud.credentials is not none) -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    command: scheduler
    depends_on:
      <<: *depends-on
      airflow_init:
        condition: service_completed_successfully

  worker_local:
    container_name: worker_local
    hostname: worker_local
    build: *build
    environment: *environment
    volumes: *volumes
    restart: always
    <<: *networks
    {% if (config.google_cloud is not none) and (config.google_cloud.credentials is not none) -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    command: celery worker -q default
    depends_on:
      <<: *depends-on
      airflow_init:
        condition: service_completed_successfully

  worker_remote:
    container_name: worker_remote
    hostname: worker_remote
    build: *build
    environment: *environment
    volumes: *volumes
    restart: always
    <<: *networks
    {% if (config.google_cloud is not none) and (config.google_cloud.credentials is not none) -%}
    secrets:
      - google_application_credentials.json
    {%- endif %}
    command: celery worker -q remote_queue
    {% if config.backend.type.value == 'local' %}
    depends_on:
      <<: *depends-on
      airflow_init:
        condition: service_completed_successfully
    {% endif %}

  apiserver:
    container_name: apiserver
    hostname: apiserver
    build:
      context: .
      dockerfile: Dockerfile.apiserver
      args:
        - HOST_USER_ID=${HOST_USER_ID}
    environment:
      - API_SERVER_DB=observatory
      - BASE_DB_URI=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}/postgres
      - OBSERVATORY_DB_URI=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@${POSTGRES_HOSTNAME}/observatory
      - OBSERVATORY_API_PORT=5002
    volumes: *volumes
    restart: always
    ports:
      - ${HOST_API_SERVER_PORT}:5002
    networks:
      - {{ config.observatory.docker_network_name }}
    healthcheck:
      test: ["CMD", "nc", "-z", "-v", "apiserver", "5002"]
      interval: 30s
      retries: 20
    command: apiserver
    entrypoint: /entrypoint-api.sh
    {% if config.backend.type.value == 'local' %}
    depends_on:
      postgres:
        condition: service_healthy
    {% endif %}

{% if config.backend.type.value == 'local' %}
  postgres:
    container_name: postgres
    hostname: postgres
    image: postgres:12.2
    environment:
      - POSTGRES_DB=airflow
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - ${HOST_POSTGRES_PATH}:/var/lib/postgresql/data
    restart: always
    networks:
      - {{ config.observatory.docker_network_name }}
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "${POSTGRES_USER}", "-d", "airflow"]
      interval: 5s
      retries: 5
{%- endif %}


{% if (config.google_cloud is not none) and (config.google_cloud.credentials is not none) -%}
secrets:
  google_application_credentials.json:
    file: ${HOST_GOOGLE_APPLICATION_CREDENTIALS}
{%- endif %}
